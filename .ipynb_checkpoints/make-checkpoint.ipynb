{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to Make Site\n",
    "This script creates a website ready to push to github. It scans the content directory for all jupyter notebooks, converts the jupyter notebook files to html, and updates the home page with links to these html files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import re\n",
    "import fileinput\n",
    "import sys\n",
    "from glob import glob\n",
    "import shutil\n",
    "from titlecase import titlecase\n",
    "\n",
    "# Set path to content\n",
    "path = 'content/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract all Jupyter notebook filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['content/python/sets.ipynb', 'content/python/if_else.ipynb', 'content/python/linked_lists.ipynb', 'content/python/pandas_basics.ipynb', 'content/python/loops.ipynb', 'content/python/list_comprehension.ipynb', 'content/python/dictionaries.ipynb', 'content/web_scraping/scraping_job_listings_with_lxml.ipynb', 'content/web_scraping/scrape_fanduel_nba_player_stats_with_scrapy.ipynb', 'content/web_scraping/scraping_stock_market_news_and_updates_with_lxml.ipynb', 'content/web_scraping/beautiful_soup_basics.ipynb', 'content/web_scraping/scrape_nba_player_rpm_stats_from_espn_with_lxml.ipynb', 'content/web_scraping/scrape_nba_player_game_logs_from_espn_with_lxml.ipynb', 'content/web_scraping/scrapy_basics.ipynb', 'content/web_scraping/scrape_historical_ohlc_stock_prices.ipynb', 'content/data_science/Fixing Assumptions.ipynb', 'content/data_science/analysis_of_boston_house_prices.ipynb', 'content/data_science/home_credit_default_risk_analysis.ipynb', 'content/data_science/In Sample Evaluation and Cross Validation.ipynb', 'content/data_science/fixing_assumptions.ipynb', 'content/data_science/Iterate and Evaluate a Naive Bayes Classifier.ipynb', 'content/data_science/Preparing Data.ipynb', 'content/data_science/preparing_data.ipynb', 'content/data_science/in_sample_evaluation_and_cross_validation.ipynb', 'content/data_engineering/plotting_s_parameter_distributions_with_matplotlib.ipynb', 'content/data_engineering/plotting_current_and_gain_distributions_with_matplotlib.ipynb', 'content/data_engineering/plotting_current_and_gain_distributions_with_matplotlib_2.ipynb']\n"
     ]
    }
   ],
   "source": [
    "# Find all jupyter notebooks in all content folders\n",
    "all_ipynb_files = [os.path.join(root, name)\n",
    "                   for root, dirs, files in os.walk(path)\n",
    "                       for name in files\n",
    "                           if name.endswith((\".ipynb\"))]\n",
    "\n",
    "# Remove make file from list\n",
    "del all_ipynb_files[0]\n",
    "\n",
    "# Filter out checkpoint files\n",
    "ipynb_files = [x for x in all_ipynb_files if \".ipynb_checkpoints\" not in x]\n",
    "\n",
    "# View file list\n",
    "print(ipynb_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract category titles and post titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Python': ['Sets', 'If Else', 'Linked Lists', 'Pandas Basics', 'Loops', 'List Comprehension', 'Dictionaries'], 'Web Scraping': ['Scraping Job Listings With Lxml', 'Scrape Fanduel Nba Player Stats With Scrapy', 'Scraping Stock Market News and Updates With Lxml', 'Beautiful Soup Basics', 'Scrape Nba Player Rpm Stats From Espn With Lxml', 'Scrape Nba Player Game Logs From Espn With Lxml', 'Scrapy Basics', 'Scrape Historical Ohlc Stock Prices'], 'Data Science': ['Fixing Assumptions', 'Analysis of Boston House Prices', 'Home Credit Default Risk Analysis', 'In Sample Evaluation and Cross Validation', 'Fixing Assumptions', 'Iterate and Evaluate a Naive Bayes Classifier', 'Preparing Data', 'Preparing Data', 'In Sample Evaluation and Cross Validation'], 'Data Engineering': ['Plotting S Parameter Distributions With Matplotlib', 'Plotting Current and Gain Distributions With Matplotlib', 'Plotting Current and Gain Distributions With Matplotlib 2']}\n"
     ]
    }
   ],
   "source": [
    "# Extract category titles and post titles\n",
    "posts = {}\n",
    "\n",
    "for post in ipynb_files:\n",
    "    # Extract category\n",
    "    category = titlecase(post.split('/')[1].replace('_', ' '))\n",
    "    \n",
    "    # Extract post\n",
    "    post_title = titlecase(post.split('/')[2].replace('.ipynb', '').replace('_', ' '))\n",
    "    \n",
    "    # Add category if not in dictionary\n",
    "    if category not in posts.keys():\n",
    "        posts[category] = []\n",
    "        # Append post to dictionary\n",
    "        posts[category].append(post_title)\n",
    "    # Otherwise, just append post\n",
    "    else:\n",
    "        posts[category].append(post_title)\n",
    "\n",
    "# View dictionary\n",
    "print(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert files to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For each file\n",
    "for file in ipynb_files:\n",
    "    # Convert into markdown\n",
    "    os.system('jupyter nbconvert --to html_embed {file}'.format(file=file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update homepage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open homepage markdown file\n",
    "f = open('README.md', 'w')\n",
    "\n",
    "header1 = \"## <center>Python • Data Science • Machine Learning</center>\"\n",
    "header2 = \"## <center>Technical Notes</center>\\n\\n\"\n",
    "\n",
    "#intro = \"Welcome to my site. I am a data scientist who is fascinated with solving challenging data science problems across a variety of fields. Check out my technical notes relating to python and data science below!\\n\"\n",
    "\n",
    "intro = \"I am a data scientist who is fascinated with solving challenging data-oriented problems across a variety of fields. I enjoy seeking hidden truths in data. Check out my technical notes on python and data science below!\"\n",
    "\n",
    "# Write title and intro\n",
    "f.write(header)\n",
    "f.write(intro)\n",
    "\n",
    "# Write categories and post titles/links\n",
    "for category, titles in posts.items():\n",
    "    f.write(\"\\n> **_\" + category + \"_**\\n\")\n",
    "    for title in titles:\n",
    "        f.write(\"> - [\" + title + \"](https://rakeshbhatia.github.io/notes/content/\" + \"_\".join([x.lower() for x in category.split(\" \")]) + \"/\" + \"_\".join([x.lower() for x in title.split(\" \")]) + \")\" + \"\\n\")\n",
    "\n",
    "f.write(\"\\nCopyright © Rakesh Bhatia, September 2019. All notes available on [GitHub](https://github.com/rakeshbhatia/notes).\")\n",
    "        \n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
